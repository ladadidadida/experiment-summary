# summary 
===
    by zhangxin

##  gan部分

> - ### 生成样本一览 (每一类16张图片 ， 图片存储在images文件夹中)
>> - 在har和ts，gl，yl中存储的为最终采用的模型的生成样本

> - ### gan网络部分
>> - <br>
>> 
>>    | 改动原因 |  作何改动及目的  |  结果  | 结果分析  |
>>    | :--------: | :-----: | :----: | :----: |
>>    | 使用wgan进行对抗训练，由于使用weight clip，gan网络的训练并不稳定，具体表现为d_loss和g_loss出现很大的波动，方差较大 | 将wgan网络修改为wgan_gp以及wgan_sn网络，wgan_gp以及wgan_sn是更好的实现lipschitz连续的方法|wgan_gp以及wgan_sn在训练过程中，dloss与gloss均表现出更好的稳定性，方差较小，wgan_sn的效果要更好|dloss更小的方差意味着网络在每一步的训练过程中均能收敛到纳什均衡上|
>>    |wgan_sn网络在训练初期依然表现出不稳定性，dloss与gloss出现很大的波动|在生成器的loss function中加入feature matching|在训练初期，gan的训练过程更为稳定，gloss波动较小|在训练初期，gan当中的gloss并不能为生成器提供稳定的梯度，加入feature matching项来稳定初期的训练 |
>>    | gan训练初期不稳定问题 | 在真假图片输入判别器时，加入高斯白噪声 | 会严重拖慢gan的收敛速度 | 由于在真假图片上叠加的高斯白噪声可能出现很大的噪声值，虽然这个噪声值很小，但是会严重拖慢判别器的收敛过程（半监督下acgan的分类性能一定程度上表明了判别器的特征提取能力）|
>>    | 在真假图片输入时，叠加高斯白噪声会拖慢gan的收敛速度 | 在真假图片输入判别器时叠加0-1./128的uniform噪声 | 叠加均匀分布的噪声会稳定gan在初期的训练，并且不会拖慢gan的收敛进程 |  |
>>    | acgan本身就是一种半监督网络，因此acgan的分类准确率可以用来大致判断生成的新样本能否可以使得分类网络获得更好的泛化能力 | 将acgan中输入的label标签量由独热码的形式改为softlabel | acgan的判别准确率由92%上升为92.5%|
>>    | 在不人为打断gan的训练的情况下，gan网络在训练后期都会发散，dloss无限下降，gloss无限上升，两者之间并不在构成动态平衡 | 在网络训练后期使用梯度裁剪限制回传的梯度太大，(可能是由于生成网络偶然间生成了比较假的图片，而判别器判断此图为假，从而给了生成一个很大的loss，从而是的梯度爆炸，网络无法收敛) | 没用 | 原因分析为由于此时的生成器层数较浅，而判别器由于使用了resnet，层数很深，所以在训练的后期，生成器的生成能力已经被开发到饱和状态，但是判别器还远远没有，在这种情况下，判别器可以轻易判别出来假图，从而引起梯度爆炸

> - ### 生成与判别网络部分
>> - <br>
>> 
>>    | 改动原因 |  作何改动及目的  |  结果  | 结果分析  |
>>    | :--------: | :-----: | :----: | :----: |
>>    | 在训练后期梯度爆炸 | 三组对比实验，同样的loss function ，只有g和d的网络深度不同 ， 分别尝试g深于d ， g与d的深度相同，g浅于d | 一般的gan网络，在2万iters时就已经可以收敛得比较好，g浅于d的情况下，gan网络在4万iters时发散，g=d的情况下，gan网络在12万时开始发散，g>d的情况下，gan网络至55万iters（60h）仍然没有发散的迹象，dloss和gloss依然维持这很小的方差，完美收敛 | 原因分析：（不确定）笔者认为，生成任务是一个远远比识别任务要难以训练的任务，所以即便在g=d的情况下，gan网络依然会发散。这是由于任务难度不同决定的，因此在使用中，使用g深度深于d的网络会更稳定 |
>>    | 在wgan中由于有weight clip,强行将d中所有的参数限制在-0.01~0.01中，因此网络可以勉强不发散，但是dloss和gloss仍然有很大的方差（见前），更改为wgan_sn后，不采用weight clip，而是采用sn的方式，即使在g深于d的情况下，网络训练后期依然不能收敛，并且在训练前期dloss和gloss有很大的方差 | 在discriminator中去掉bn层，只采用spectral norm，由于bn是一个很强力的加速收敛，提升网络泛化性能的方法，因此希望去掉bn层可以稳定训练 | works |spectral norm本身也可以加速收敛，同时起到了限制d参数有界的作用，只是用sn网络依然可以训练。去掉bn这种强力的加速收敛的工具削弱了d的能力，但是稳定了gan的训练|
>>    | 生成网络中，使用deconv层是一种对上一层图像每一个点的不平等利用，生成图像在细节处的表现并不平滑，会造成分辨率不够 | 使用双线性插值先上采样，然后使用卷积层来叠加生成器的层数更深 | 无明显差别，从生成样本来看，upsampling的这种方式会让网络收敛的更快，即更早的时候，生成波形就可以表现得更平滑，但是deconv需要在继续训练一段时间才能达到相同的效果。 | 虽然说没有什么太大的差别，还是采用upsample的方式更好|
>>    | 为了避免训练后期梯度爆炸，稳定gan网络的训练，在g中加深网络深度，虽说网络训练稳定了很多，但是生成样本质量很差 | 在g中使用resnet构建，并且遵循resnet做判别器的原则来设计生成网络网络 | 生成样本质量大幅提升，acgan的acc最大值上升0.7 | 原因分析：生成任务远比判别任务要难，在判别任务中，例如res18，res34 ，res50 ，res101，不管多深的识别网络，会引起梯度消失的层，例如conv_block，永远都不会超过三层，其余层全部都是res_block（resblock不会引起梯度消失），在生成网络中我们采用了只是用三层conv——block的结构，搭建了resnet18来生成波形。|
>>    | 为了提升生成样本的逼真度，在网络中加入self attention | 在生成器与判别器的最后两层插入self attention | 对比了有sa和无sa的生成数据集对cnn分类网络性能的提升的影响，发现sa可以提升生成图片更逼真，但是在做提升cnn性能方面，没有很大的作用 | sa可以提升图像的逼真度，但是作为数据增强方面来说，sa并不能起到很大的作用 |
>>    | 生成图片相似度很高，也就是生成模型并不具备很好的泛化性能 | 分析原因：由于generator中存在bn层，bn层是在feature的方向上，做norm。因此会引入样本和样本之间的耦合性，因此在这里去掉生成器中的bn层 | 网络没办法收敛 |
>>    | 使用layer norm 以及instance norm来替代batch norm | gan网络可以收敛，但是acgan的acc最大值明显低于使用了bn的情况 | layer norm 和instance norm 并不能给生成网络提供很好的加速收敛的效果，因此在g中必须使用bn层。 |
>>    | 在网络中加回bn层，为了解决样本之间的耦合性，生成同类样本太过单一的情况，在生成网络中使用dropout层，在训练和实际生成中，dropout层均呈开启状态，即在生成时，通过参数的选择的不同来实现解决bn耦合性的问题 | 同一batch生成图像依然很像，这是由于bn的存在引起的，但是使用了dropout层之后不同batch之间的图像相似度降低 | 在生成图像中使用dropout可以增加图像的多样性 |
>>    | 增加样本多样性 | 在生成网络的每一层都concat进去高斯白噪声，用以改善样本的多样性| 肉眼观察，没有很大的作用 |


## cnn部分

>> - <br>
>> 
>>    |  作何改动及目的  |  结果  | 结果分析  |
>>    | :-----: | :----: | :----: |
>>    | 对比fixed（即：样本按类的比例生成样本）与random（即：完全随机生成样本，这样子生成样本的每一类数量大致相等） |  fixed数据集做数据增强要优于random0.3%  |  从生成的样本来看，由于训练集中某一类的样本数量太少，正如在训练识别网络中一样，少样本训练的生成网络，也无法生成样本质量很高的样本，也就是生成网络并不具备很好的泛化性能，因此使用fixed数据集会取得更好的效果 |
>>    | 生成样本：原始样本 比例 对 提升性能的影响（har ， cnn），设置六组对照实验，1:1,  1:1.5,  1:2，  1:2.5  ，1:3，  1:4|  1:1对分类性能的提升最大 |    |
>>    | 在生成样本与原始样本1:1的情况下，如何使用生成样本以及原始样本来对cnn网络进行训练的问题，设置三组对照试验1:1 , 3:1 ， 15:5（并不是3:1） |  15:5的结果最差，1：1与3:1的性能提升效果接近，性能提升相差并不是很大 | 不能在一段时间内，大量得使用生成样本进行训练 |
>>    |  在wgan_sn+gres18+dres7的网络结构下，生成数据集对网络性能的提升仅有93.6 -> 94.3% ，此时在生成器中卷积核的大小为5* 2 与 5*1，将卷积核调大，重新生成图像  |  性能提升：94.3% -> 94.6%  |  在生成中，大卷积核代表着生成时更容易掌握全局信息，（即：对应感受野大）|

>> - 在cnn中，使用生成样本对resnet是没有起到提升性能的作用的，仅仅只对cnn网络的性能有提升。
>> - 在har CNN中，分类性能从93.8% -> 94.6%